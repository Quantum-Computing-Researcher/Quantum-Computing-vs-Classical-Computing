#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# ----------------------------------------------------------------------------------------------------------------
# GPU-accelerated Empirical Evaluation: Quantum SWAP Test (Noiseless) ‚Äì Quantum Baseline
"""18 Swap Test

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/i222070tabidahusmani/18-swap-test.193fa8ad-4cca-4717-a971-0c094eb963b2.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251121/auto/storage/goog4_request%26X-Goog-Date%3D20251121T134303Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2f4573791d355bca03f74af6d55622fc5d8ab904a8b3a7a27aa5b64effe30e2ba823c9c27b806f11fc160509c3500769ea3f277402112a30c692a3305fb588501622a4bbd35daeef13100ccce3a19af5d38176f5f7763c41ade504fb1cd5351d938794d8bcc0c33594af924c9da11bdf96f588ed276f477a0446dbe03e355f4807d97c3333273d83bf4d864a7991fb7fe519938b681c8918d5d2c212f372c332f041ae5100d5f8782e1cbe4dff7e09041fe22a4c981efb0e5fbb72d0e7e9fe8b15e2e9ccda7d8cd3845f9f689db3be4084f57ec3b17a1ee3957f2372cd2d2ef61dee33ab618098b596e65b490fbaff59dd6ba6d93a3f053a3e8fc922d5d43f66
"""

"""
GPU-accelerated Empirical Evaluation: Quantum SWAP Test (Noiseless) ‚Äì Quantum Baseline

This script mirrors the classical baseline's parameters, metrics, and evaluation strategy.
It produces four benchmarks:
  1) Performance     ‚Äì runtime, memory, accuracy
  2) Scalability     ‚Äì runtime & memory vs problem size
  3) Reliability     ‚Äì stability of results across seeds
  4) Carbon footprint‚Äì CO‚ÇÇ based solely on Performance runtimes

"""
# ----------------------------------------------------------------------------------------------------------------

# Notes: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

# Code focuses on Performance, Scalability, Reliability, Carbon footprints
# Output folders are:
    #   Performance = runtime
    #   Scalability = growth of runtime as N increases (digits/bits).
    #   Reliability = success rate + dispersion across repetitions.
    #   Carbon footprints = derived *only* from PERFORMANCE totals
    #   (sum of successful wall-times), device power 65 Watts fixed for comparasion, PUE 1.2 fixed, 
    #   country carbon intensity (kg CO2/kWh). I did not use scalability or reliability results for CO2.

#      Carbon Data File: 
#      Uses ONLY Performance runtimes (not Scalability/Reliability), 
#      Placed on my Desktop Excel of country intensities "Filtered CO2 intensity 236 Countries.xlsx"
#      (CSV or XLSX; year column optional. I have selected --year-select latest.)
# ----------------------------------------------------------------------------------------------------------------


# ------------********------------ Imports
#These imports provide system-level utilities for timing, memory profiling, filesystem handling, and warnings.
#Dataclasses and typing helpers support structured data representation and clearer interfaces.
#Threading and concurrent futures enable parallel task execution and coordination.

import os, sys, time, tracemalloc, pathlib, warnings, math
from dataclasses import dataclass
from typing import List, Tuple, Dict, Any
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

# ------------********-------------
# ------------********------------- GPU Setup and Dependencies
# ------------********-------------
print("üîç Checking GPU availability...")

HAS_GPU = False
cp = None

try:
    import cupy as cp
    # Test if GPU is available and working
    with cp.cuda.Device(0):
        # Simple test to verify GPU functionality
        test_array = cp.zeros(10, dtype=cp.float32)
        result = cp.sum(test_array)
        HAS_GPU = True
        print(f"‚úÖ GPU detected: {cp.cuda.runtime.getDeviceProperties(0)['name'].decode()}")
        print(f"   Memory: {cp.cuda.Device().mem_info[1] / 1e9:.2f} GB")
        print(f"   Compute Capability: {cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}")
except ImportError:
    print("‚ùå CuPy not available, falling back to NumPy")
    import numpy as cp
except Exception as e:
    print(f"‚ö†Ô∏è  GPU setup failed: {e}, falling back to NumPy")
    import numpy as cp

# If GPU failed, use NumPy
if not HAS_GPU:
    import numpy as cp
    print("üîÑ Using NumPy (CPU) backend")

# Install required packages
def _ensure(pkgs: List[str]):
    import importlib, subprocess
    missing = []
    for p in pkgs:
        try:
            importlib.import_module(p)
        except ImportError:
            missing.append(p)
    if missing:
        print(f"[setup] Installing missing packages: {missing}")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", *missing])
        except Exception as e:
            print(f"[setup] Auto-install failed: {e}")

_ensure(["pandas", "matplotlib", "openpyxl", "psutil", "scikit-learn"])

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

# GPU utility functions
def get_device_name() -> str:
    """Get current device name"""
    if HAS_GPU:
        try:
            return f"GPU: {cp.cuda.runtime.getDeviceProperties(0)['name'].decode()}"
        except:
            return "GPU: Unknown"
    return "CPU: NumPy"

def safe_gpu_cleanup():
    #Safely cleanup GPU memory
    if HAS_GPU:
        try:
            cp.get_default_memory_pool().free_all_blocks()
        except:
            pass

def to_numpy(x):
    #Safely convert CuPy array to NumPy array
    if HAS_GPU and isinstance(x, cp.ndarray):
        return cp.asnumpy(x)
    return x

def to_cupy(x):
    """Safely convert NumPy array to CuPy array"""
    if HAS_GPU and isinstance(x, np.ndarray):
        return cp.asarray(x)
    return x

# Thread-safe GPU operations
_gpu_lock = threading.Lock()

def run_experiment_thread_safe(args):
    
    #Thread-safe GPU experiment runner.
    #Uses a lock to prevent multiple threads from accessing GPU simultaneously.
    
    dimension, pairs, seed = args
    with _gpu_lock:  # Ensure only one thread uses GPU at a time
        return _run_single_experiment(dimension, pairs, seed)

# ------------********-------------
# ========================= Quantum SWAP Test Core =========================
# ------------********-------------

def generate_vector_pairs(dimension: int, pairs: int, distribution: str = "normal") -> Tuple[cp.ndarray, cp.ndarray]:
    """Generate random vector pairs on GPU"""
    if HAS_GPU:
        if distribution == "uniform":
            A = cp.random.uniform(-1.0, 1.0, size=(pairs, dimension)).astype(cp.float64)
            B = cp.random.uniform(-1.0, 1.0, size=(pairs, dimension)).astype(cp.float64)
        else:  # normal
            A = cp.random.standard_normal(size=(pairs, dimension), dtype=cp.float64)
            B = cp.random.standard_normal(size=(pairs, dimension), dtype=cp.float64)
    else:
        rng = np.random.default_rng(seed=42)  # Fallback to NumPy
        if distribution == "uniform":
            A = rng.uniform(-1.0, 1.0, size=(pairs, dimension)).astype(np.float64)
            B = rng.uniform(-1.0, 1.0, size=(pairs, dimension)).astype(np.float64)
        else:  # normal
            A = rng.standard_normal(size=(pairs, dimension), dtype=np.float64)
            B = rng.standard_normal(size=(pairs, dimension), dtype=np.float64)
        A, B = to_cupy(A), to_cupy(B)

    return A, B

def normalize_vectors(A: cp.ndarray, B: cp.ndarray) -> Tuple[cp.ndarray, cp.ndarray]:
    """Normalize vectors to unit length for amplitude encoding"""
    norms_A = cp.linalg.norm(A, axis=1, keepdims=True)
    norms_B = cp.linalg.norm(B, axis=1, keepdims=True)

    # Avoid division by zero
    norms_A = cp.maximum(norms_A, 1e-16)
    norms_B = cp.maximum(norms_B, 1e-16)

    A_normalized = A / norms_A
    B_normalized = B / norms_B

    return A_normalized, B_normalized

def compute_cosine_similarity(A: cp.ndarray, B: cp.ndarray) -> cp.ndarray:
    """Compute cosine similarity between vector pairs"""
    # Dot products
    dots = cp.sum(A * B, axis=1)

    # Cosine similarity = dot product (since vectors are normalized)
    cosine_similarity = dots

    # Clamp to valid range due to numerical precision
    cosine_similarity = cp.clip(cosine_similarity, -1.0, 1.0)

    return cosine_similarity

def swap_test_probability(cosine_similarity: cp.ndarray) -> cp.ndarray:
    """Compute SWAP test probability p0 = (1 + |<x|y>|^2) / 2"""
    cosine_sq = cosine_similarity ** 2
    p0 = 0.5 * (1.0 + cosine_sq)
    return p0

def sample_swap_measurements(p0: cp.ndarray, shots: int) -> cp.ndarray:
    """Sample SWAP test measurements"""
    if HAS_GPU:
        # Generate random samples on GPU
        samples = cp.random.random(size=(len(p0), shots))
        # Count successes (samples < p0)
        successes = cp.sum(samples < p0[:, cp.newaxis], axis=1)
        p0_estimated = successes.astype(cp.float64) / shots
    else:
        # Fallback to NumPy
        p0_np = to_numpy(p0)
        samples = np.random.random(size=(len(p0_np), shots))
        successes = np.sum(samples < p0_np[:, np.newaxis], axis=1)
        p0_estimated = successes.astype(np.float64) / shots
        p0_estimated = to_cupy(p0_estimated)

    return p0_estimated

def compute_fidelity_metrics(A: cp.ndarray, B: cp.ndarray, p0_ideal: cp.ndarray, p0_estimated: cp.ndarray) -> Dict[str, float]:
    """Compute various fidelity and error metrics"""
    # Convert to numpy for reliable computation
    A_np = to_numpy(A)
    B_np = to_numpy(B)
    p0_ideal_np = to_numpy(p0_ideal)
    p0_estimated_np = to_numpy(p0_estimated)

    # Compute cosine similarities for ground truth
    dots = np.sum(A_np * B_np, axis=1)
    cosine_truth = np.clip(dots, -1.0, 1.0)  # Already normalized

    # SWAP test estimates
    swap_estimate = 2.0 * p0_estimated_np - 1.0  # Should approximate cosine_truth^2
    cosine_sq_truth = cosine_truth ** 2

    # Error metrics
    mse = float(np.mean((swap_estimate - cosine_sq_truth) ** 2))
    mean_abs_error = float(np.mean(np.abs(swap_estimate - cosine_sq_truth)))

    # Fidelity-like metric (how well we estimate the squared overlap)
    fidelity = max(0.0, 1.0 - mean_abs_error)

    return {
        "mse": mse,
        "mean_abs_error": mean_abs_error,
        "fidelity": fidelity,
        "mean_cosine_sq": float(np.mean(cosine_sq_truth)),
        "mean_swap_estimate": float(np.mean(swap_estimate))
    }

def _run_single_experiment(dimension: int, pairs: int, seed: int) -> dict:
    """
    Core experiment logic - run single SWAP Test experiment.
    """
    # Fixed parameters
    distribution = "normal"
    shots = 4096  # Measurement shots

    # Set random seed
    np.random.seed(seed)
    if HAS_GPU:
        cp.random.seed(seed)

    tracemalloc.start()
    t0 = time.perf_counter()

    try:
        # Generate vector pairs on GPU
        A, B = generate_vector_pairs(dimension, pairs, distribution)

        # Normalize for amplitude encoding
        A_norm, B_norm = normalize_vectors(A, B)

        # Compute cosine similarity (inner product of normalized vectors)
        cosine_sim = compute_cosine_similarity(A_norm, B_norm)

        # Compute ideal SWAP test probability
        p0_ideal = swap_test_probability(cosine_sim)

        # Sample measurements
        p0_estimated = sample_swap_measurements(p0_ideal, shots)

        # Compute metrics
        metrics = compute_fidelity_metrics(A_norm, B_norm, p0_ideal, p0_estimated)

        success = True

    except Exception as e:
        print(f"‚ùå Experiment failed for dimension={dimension}, pairs={pairs}, seed={seed}: {e}")
        metrics = {
            "mse": float('inf'),
            "mean_abs_error": float('inf'),
            "fidelity": 0.0,
            "mean_cosine_sq": 0.0,
            "mean_swap_estimate": 0.0
        }
        success = False

    runtime = time.perf_counter() - t0
    _, peak = tracemalloc.get_traced_memory()
    tracemalloc.stop()

    # Cleanup GPU memory
    safe_gpu_cleanup()

    return {
        "dimension": int(dimension),
        "pairs": int(pairs),
        "seed": int(seed),
        "shots": int(shots),
        "mse": float(metrics["mse"]),
        "mean_abs_error": float(metrics["mean_abs_error"]),
        "fidelity": float(metrics["fidelity"]),
        "mean_cosine_sq": float(metrics["mean_cosine_sq"]),
        "mean_swap_estimate": float(metrics["mean_swap_estimate"]),
        "success": bool(success),
        "runtime_s": float(runtime),
        "peak_mem_mb": float(peak / (1024**2)),
        "device": get_device_name()
    }
# ------------********-------------
# ============================== Carbon I/O ==============================
# ------------********-------------

def resolve_excel_path(excel_arg: str) -> str:
    p = pathlib.Path(excel_arg)
    if p.is_absolute() and p.exists():
        return str(p)
    desktop = pathlib.Path.home() / "Desktop" / excel_arg
    return str(desktop if desktop.exists() else p)

def load_carbon_excel(path: str, year_select: str = "latest") -> pd.DataFrame:
    df = pd.read_excel(path)
    cols = {c.lower(): c for c in df.columns}
    cand_country = next((v for k, v in cols.items() if "country" in k or "nation" in k or k == "location"), None)
    if cand_country is None:
        raise ValueError("No 'Country' column found.")
    cand_year = next((v for k, v in cols.items() if "year" in k or "date" in k), None)
    cand_intensity = next((v for k, v in cols.items()
                           if "intensity" in k or ("co2" in k and "kwh" in k) or "kgco2" in k or "gco2" in k), None)
    if cand_intensity is None:
        numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
        if cand_year in numeric_cols:
            numeric_cols.remove(cand_year)
        if not numeric_cols:
            raise ValueError("No numeric intensity column detected.")
        cand_intensity = numeric_cols[0]
    keep = [cand_country] + ([cand_year] if cand_year else []) + [cand_intensity]
    df = df[keep].copy()
    df.columns = ["Country", "Year", "Intensity"] if len(keep) == 3 else ["Country", "Intensity"]
    if "Year" in df.columns and year_select.lower() == "latest":
        df = df.sort_values(["Country", "Year"]).groupby("Country", as_index=False).tail(1)

    # Heuristic unit fix: if median looks like g/kWh, convert to kg/kWh
    med = float(df["Intensity"].dropna().median())
    if med > 50:
        df["Intensity"] = df["Intensity"] / 1000.0

    return df.dropna(subset=["Country", "Intensity"]).reset_index(drop=True)

def compute_carbon(perf_df: pd.DataFrame, intensity_df: pd.DataFrame,
                   power_watts: float, pue: float, combine: bool) -> tuple[pd.DataFrame, pd.DataFrame]:
    total_runtime_s = float(perf_df["runtime_s"].sum())
    kWh_total = power_watts * pue * total_runtime_s / 3_600_000.0
    df = intensity_df.copy()
    df["kWh"] = kWh_total
    df["kgCO2e"] = df["Intensity"] * df["kWh"]

    # ALWAYS return country-wise results (ignore combine parameter)
    carbon_output = df.sort_values("kgCO2e", ascending=False)

    summary = pd.DataFrame({
        "total_runtime_s": [total_runtime_s],
        "power_watts": [power_watts],
        "PUE": [pue],
        "kWh_total": [kWh_total],
        "median_intensity_kg_per_kWh": [float(df["Intensity"].median())],
        "mean_kgCO2e_across_countries": [float(df["kgCO2e"].mean())],
        "device": [perf_df["device"].iloc[0] if "device" in perf_df.columns else "Unknown"],
        "combine_mode": [combine],
        "countries_analyzed": [len(df)]
    })
    return carbon_output, summary

# ------------********-------------
# ============================== Plot Helpers ==============================
# ------------********-------------

plt_kwargs = dict(dpi=140, bbox_inches="tight")

def _boxplot_with_labels(data, labels):
    # Matplotlib 3.9 renamed 'labels' -> 'tick_labels'
    try:
        plt.boxplot(data, tick_labels=labels)
    except TypeError:
        plt.boxplot(data, labels=labels)

def plot_performance(df: pd.DataFrame, outdir: str):
    # Runtime vs dimension
    g = df.groupby("dimension")["runtime_s"].mean().reset_index()
    plt.figure(figsize=(10, 6))
    plt.plot(g["dimension"], g["runtime_s"], marker="o", linewidth=2, markersize=8)
    plt.xscale("log", base=2)
    plt.xlabel("Vector Dimension")
    plt.ylabel("Runtime (s)")
    plt.title(f"Performance: Runtime vs Dimension\n{get_device_name()}")
    plt.grid(True)
    plt.savefig(os.path.join(outdir, "perf_runtime_vs_dimension.png"), **plt_kwargs)
    plt.close()

    # Memory usage vs dimension
    g2 = df.groupby("dimension")["peak_mem_mb"].mean().reset_index()
    plt.figure(figsize=(10, 6))
    plt.plot(g2["dimension"], g2["peak_mem_mb"], marker="s", linewidth=2, markersize=8, color='green')
    plt.xscale("log", base=2)
    plt.xlabel("Vector Dimension")
    plt.ylabel("Memory Usage (MB)")
    plt.title(f"Performance: Memory vs Dimension\n{get_device_name()}")
    plt.grid(True)
    plt.savefig(os.path.join(outdir, "perf_memory_vs_dimension.png"), **plt_kwargs)
    plt.close()

    # Fidelity vs dimension
    g3 = df.groupby("dimension")["fidelity"].mean().reset_index()
    plt.figure(figsize=(10, 6))
    plt.plot(g3["dimension"], g3["fidelity"], marker="^", linewidth=2, markersize=8, color='purple')
    plt.xscale("log", base=2)
    plt.xlabel("Vector Dimension")
    plt.ylabel("Fidelity")
    plt.title(f"Performance: Fidelity vs Dimension\n{get_device_name()}")
    plt.grid(True)
    plt.savefig(os.path.join(outdir, "perf_fidelity_vs_dimension.png"), **plt_kwargs)
    plt.close()

# ------------********-------------
def plot_scalability(df: pd.DataFrame, outdir: str):
    # Runtime vs dimension (log-log)
    g = df.groupby("dimension")["runtime_s"].mean().reset_index()
    plt.figure(figsize=(8, 6))
    plt.loglog(g["dimension"], g["runtime_s"], marker="o", linewidth=2, markersize=8)
    plt.xlabel("Vector Dimension")
    plt.ylabel("Runtime (s)")
    plt.title(f"Scalability: Runtime vs Dimension (log-log)\n{get_device_name()}")
    plt.grid(True, which="both")
    plt.savefig(os.path.join(outdir, "scal_runtime_vs_dimension.png"), **plt_kwargs)
    plt.close()

    # Memory vs dimension
    g2 = df.groupby("dimension")["peak_mem_mb"].mean().reset_index()
    plt.figure(figsize=(8, 6))
    plt.semilogy(g2["dimension"], g2["peak_mem_mb"], marker="^", linewidth=2, markersize=8, color='green')
    plt.xlabel("Vector Dimension")
    plt.ylabel("Memory Usage (MB)")
    plt.title(f"Scalability: Memory vs Dimension\n{get_device_name()}")
    plt.grid(True)
    plt.savefig(os.path.join(outdir, "scal_memory_vs_dimension.png"), **plt_kwargs)
    plt.close()

# ------------********-------------
def plot_reliability(df: pd.DataFrame, outdir: str):
    # Error distribution by dimension
    data = [df[df["dimension"] == d]["mse"].values for d in sorted(df["dimension"].unique())]
    plt.figure(figsize=(10, 6))
    _boxplot_with_labels(data, labels=[f"Dim={d}" for d in sorted(df["dimension"].unique())])
    plt.yscale("log")
    plt.xlabel("Vector Dimension")
    plt.ylabel("MSE (log scale)")
    plt.title(f"Reliability: Error Distribution by Dimension\n{get_device_name()}")
    plt.grid(True)
    plt.savefig(os.path.join(outdir, "rel_error_distribution.png"), **plt_kwargs)
    plt.close()

    # Success rate (should be 100% for noiseless)
    success_rates = df.groupby("dimension")["success"].mean().reset_index()
    plt.figure(figsize=(8, 6))
    plt.plot(success_rates["dimension"], success_rates["success"],
             marker="o", linewidth=2, markersize=8)
    plt.xscale("log", base=2)
    plt.xlabel("Vector Dimension")
    plt.ylabel("Success Rate")
    plt.title(f"Reliability: Success Rate vs Dimension\n{get_device_name()}")
    plt.grid(True)
    plt.savefig(os.path.join(outdir, "rel_success_rate.png"), **plt_kwargs)
    plt.close()

    # Fidelity heatmap
    pivot_data = df.pivot_table(values="fidelity", index="dimension", columns="pairs", aggfunc="mean")
    plt.figure(figsize=(10, 6))
    plt.imshow(pivot_data.values, aspect="auto", cmap="viridis", origin="lower")
    plt.colorbar(label="Fidelity")
    plt.xticks(range(len(pivot_data.columns)), pivot_data.columns)
    plt.yticks(range(len(pivot_data.index)), pivot_data.index)
    plt.xlabel("Number of Pairs")
    plt.ylabel("Vector Dimension")
    plt.title(f"Reliability: Fidelity Heatmap\n{get_device_name()}")
    plt.tight_layout()
    plt.savefig(os.path.join(outdir, "rel_fidelity_heatmap.png"), **plt_kwargs)
    plt.close()

# ------------********-------------
def plot_carbon(df: pd.DataFrame, combine: bool, outdir: str):
    """Generate carbon footprint plots - ALWAYS country-wise"""
    # Top 15 highest emissions
    top = df.nlargest(15, "kgCO2e")
    plt.figure(figsize=(12, 8))
    plt.barh(top["Country"][::-1], top["kgCO2e"][::-1], color='red', alpha=0.7)
    plt.xlabel("kg CO2e (higher = dirtier grid)", fontsize=12)
    plt.title(f"Carbon: Top 15 Highest Emissions\n{get_device_name()}", fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(os.path.join(outdir, "carbon_top15.png"), **plt_kwargs)
    plt.close()

    # Bottom 15 lowest emissions
    bot = df.nsmallest(15, "kgCO2e")
    plt.figure(figsize=(12, 8))
    plt.barh(bot["Country"][::-1], bot["kgCO2e"][::-1], color='green', alpha=0.7)
    plt.xlabel("kg CO2e (lower = cleaner grid)", fontsize=12)
    plt.title(f"Carbon: Bottom 15 Lowest Emissions\n{get_device_name()}", fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(os.path.join(outdir, "carbon_bottom15.png"), **plt_kwargs)
    plt.close()

    # Distribution histogram
    plt.figure(figsize=(10, 6))
    plt.hist(df["kgCO2e"], bins=30, alpha=0.7, edgecolor='black', color='orange')
    plt.xlabel("kg CO2e for this experiment", fontsize=12)
    plt.ylabel("Frequency", fontsize=12)
    plt.title(f"Carbon: Emission Distribution\n{get_device_name()}", fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.savefig(os.path.join(outdir, "carbon_distribution.png"), **plt_kwargs)
    plt.close()

    # CDF plot
    xs = np.sort(df["kgCO2e"].values)
    ys = np.arange(1, len(xs) + 1) / len(xs)
    plt.figure(figsize=(10, 6))
    plt.plot(xs, ys, linewidth=2, color='purple')
    plt.xlabel("kg CO2e", fontsize=12)
    plt.ylabel("CDF", fontsize=12)
    plt.title(f"Carbon: Cumulative Distribution\n{get_device_name()}", fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.savefig(os.path.join(outdir, "carbon_cdf.png"), **plt_kwargs)
    plt.close()
# ------------********-------------
# ============================== Utility Functions ==============================
# ------------********-------------

def ensure_dir(d: str):
    """Ensure directory exists"""
    os.makedirs(d, exist_ok=True)

def to_excel(dfs: Dict[str, pd.DataFrame], path: str):
    """Save multiple DataFrames to Excel with different sheets"""
    with pd.ExcelWriter(path, engine="openpyxl") as w:
        for name, df in dfs.items():
            df.to_excel(w, index=False, sheet_name=name[:31])

# ------------********-------------
# ============================== Main Experiment Runner ==============================
# ------------********-------------

def run_swap_test_experiment():
   
    #Main SWAP Test experiment runner with hardcoded parameters for Kaggle.
    #Equivalent to: --dim-min 128 --dim-max 4096 --pairs 1000 --repeats 2
    #              --device-power-watts 65 --pue 1.2 --combine
   
    # Experiment parameters
    dim_min = 128
    dim_max = 4096
    pairs = 1000
    trials = 2   # trials per dimension
    workers = 4   # Number of parallel threads

    # Generate dimensions (powers of 2)
    dimensions = []
    d = 128
    while d <= dim_max:
        dimensions.append(d)
        d *= 2

    # Carbon parameters
    device_power_watts = 65.0
    pue = 1.2
    combine = True

    print(f"üöÄ Starting Quantum SWAP Test experiments on {get_device_name()}")
    print(f"üîß Configuration:")
    print(f"   Dimensions: {dimensions}")
    print(f"   Vector pairs per dimension: {pairs}")
    print(f"   Trials per dimension: {trials}")
    print(f"   Shots per SWAP test: 4096")
    print(f"   Distribution: normal")
    print(f"   Workers: {workers}")
    print(f"   Device power: {device_power_watts}W")
    print(f"   PUE: {pue}")
    print(f"   Combine carbon: {combine}")

    # Create output folders
    perf_dir = os.path.join(os.getcwd(), "Performance")
    scal_dir = os.path.join(os.getcwd(), "Scalability")
    rel_dir  = os.path.join(os.getcwd(), "Reliability")
    carb_root = os.path.join(os.getcwd(), "Carbon footprints")
    carb_dir  = os.path.join(carb_root, "carbon_by_country")

    for d in [perf_dir, scal_dir, rel_dir, carb_dir]:
        ensure_dir(d)

    # Prepare jobs
    jobs = []
    for dimension in dimensions:
        for i in range(trials):
            seed = 1000 + 17 * dimension + 31 * pairs + i
            jobs.append((dimension, pairs, seed))

    all_rows = []

    def _consume(row):
        """Process completed job results"""
        all_rows.append(row)
        status = "‚úÖ" if row["success"] else "‚ùå"
        print(f"  {status} dim={row['dimension']}, pairs={row['pairs']}, seed={row['seed']} "
              f"(runtime={row['runtime_s']:.6f}s, fidelity={row['fidelity']:.3f})")

    # Execute jobs with thread-based parallelization
    print(f"üîÄ Running {len(jobs)} jobs in parallel with {workers} threads...")

    if workers > 1 and len(jobs) > 1:
        with ThreadPoolExecutor(max_workers=workers) as executor:
            # Submit all jobs
            future_to_job = {executor.submit(run_experiment_thread_safe, job): job for job in jobs}

            # Collect results as they complete
            for future in as_completed(future_to_job):
                try:
                    result = future.result()
                    _consume(result)
                except Exception as e:
                    job = future_to_job[future]
                    print(f"‚ùå Job failed dimension={job[0]}, pairs={job[1]}, seed={job[2]}: {e}")
    else:
        # Fallback to sequential execution
        for job in jobs:
            result = run_experiment_thread_safe(job)
            _consume(result)

    # Check if we have any successful results
    if not all_rows:
        print("‚ùå All jobs failed! Running sequentially as fallback...")
        for job in jobs:
            try:
                result = _run_single_experiment(job[0], job[1], job[2])
                _consume(result)
            except Exception as e:
                print(f"‚ùå Sequential fallback also failed for dimension={job[0]}, pairs={job[1]}, seed={job[2]}: {e}")

    if not all_rows:
        print("üí• CRITICAL: No experiments completed successfully!")
        return None

    perf_df = pd.DataFrame(all_rows)

# ------------********---------------------------- Performance Results ----------------
    print("üìä Generating Performance results...")
    perf_excel = os.path.join(perf_dir, "performance_results.xlsx")

    # Only aggregate successful runs
    success_df = perf_df[perf_df["success"]]
    if len(success_df) > 0:
        perf_agg = success_df.groupby("dimension").agg({
            "runtime_s": ["mean", "std"],
            "peak_mem_mb": ["mean", "std"],
            "fidelity": ["mean", "std"],
            "mse": ["mean", "std"],
            "mean_abs_error": ["mean", "std"]
        }).reset_index()
        # Flatten column names
        perf_agg.columns = ['_'.join(col).strip('_') for col in perf_agg.columns.values]
    else:
        perf_agg = pd.DataFrame({"note": ["No successful experiments"]})

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        to_excel({
            "raw_runs": perf_df,
            "aggregated": perf_agg
        }, perf_excel)

    plot_performance(perf_df, perf_dir)

# ------------********-------------------------- Scalability Results ----------------
    print("üìà Generating Scalability results...")
    scal_excel = os.path.join(scal_dir, "scalability_results.xlsx")

    # Compute scaling coefficients only for successful runs
    success_df = perf_df[perf_df["success"]]
    if len(success_df) > 0 and len(success_df["dimension"].unique()) >= 2:
        # Log-log fit for scaling analysis
        scaling_data = success_df.groupby("dimension")["runtime_s"].mean().reset_index()
        log_dim = np.log(scaling_data["dimension"].values)
        log_time = np.log(scaling_data["runtime_s"].values + 1e-12)

        # Only compute if we have enough data and variation
        if len(log_dim) >= 2 and np.std(log_dim) > 1e-6 and np.std(log_time) > 1e-6:
            try:
                scaling_coeff = np.polyfit(log_dim, log_time, 1)[0]
                scaling_summary = pd.DataFrame({
                    "parameter": ["scaling_exponent"],
                    "value": [scaling_coeff],
                    "description": ["Exponent in time ~ dimension^exponent"]
                })
            except:
                scaling_summary = pd.DataFrame({
                    "parameter": ["scaling_exponent"],
                    "value": [np.nan],
                    "description": ["Numerical issues in scaling analysis"]
                })
        else:
            scaling_summary = pd.DataFrame({
                "parameter": ["scaling_exponent"],
                "value": [np.nan],
                "description": ["Insufficient data variation for scaling analysis"]
            })
    else:
        scaling_summary = pd.DataFrame({
            "parameter": ["scaling_exponent"],
            "value": [np.nan],
            "description": ["No successful experiments for scaling analysis"]
        })

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        to_excel({
            "raw_data": perf_df[["dimension", "pairs", "runtime_s", "peak_mem_mb", "success"]],
            "scaling_analysis": scaling_summary
        }, scal_excel)

    plot_scalability(perf_df, scal_dir)

# ------------********--------------------------- Reliability Results ----------------
    print("üéØ Generating Reliability results...")
    rel_excel = os.path.join(rel_dir, "reliability_results.xlsx")

    reliability_analysis = perf_df.groupby("dimension").agg({
        "mse": ["mean", "std", "min", "max"],
        "fidelity": ["mean", "std"],
        "mean_abs_error": ["mean", "std"],
        "success": "mean",
        "runtime_s": ["mean", "std"]
    }).reset_index()
    reliability_analysis.columns = ['_'.join(col).strip('_') for col in reliability_analysis.columns.values]

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        to_excel({
            "error_analysis": reliability_analysis,
            "raw_results": perf_df[["dimension", "pairs", "seed", "mse", "fidelity", "mean_abs_error", "success"]]
        }, rel_excel)

    plot_reliability(perf_df, rel_dir)

# ------------********---------------------------- Carbon Footprint Results ----------------
    print("üåç Generating Carbon footprint results...")

    # Load carbon data from Kaggle input directory
    excel_path = "/kaggle/input/masters/Filtered CO2 intensity 236 Countries.xlsx"
    intensity_df = None

    try:
        # Try to load from the exact path
        intensity_df = pd.read_excel(excel_path)
        print(f"‚úÖ Loaded carbon data from: {excel_path}")
        print(f"   Columns found: {list(intensity_df.columns)}")
        print(f"   Countries loaded: {len(intensity_df)}")

        # Auto-detect and process columns
        cols = {c.lower(): c for c in intensity_df.columns}
        cand_country = next((v for k,v in cols.items() if "country" in k or "nation" in k or k=="location"), None)
        if cand_country is None:
            raise ValueError("No 'Country' column found.")

        cand_intensity = next((v for k,v in cols.items() if "intensity" in k or ("co2" in k and ("kwh" in k or "/kwh" in k)) or "kgco2" in k or "gco2" in k), None)

        if cand_intensity is None:
            numeric_cols = [c for c in intensity_df.columns if pd.api.types.is_numeric_dtype(intensity_df[c])]
            if not numeric_cols:
                raise ValueError("No numeric intensity column detected.")
            cand_intensity = numeric_cols[0]

        # Keep only necessary columns
        intensity_df = intensity_df[[cand_country, cand_intensity]].copy()
        intensity_df.columns = ["Country", "Intensity"]

        # Convert gCO2/kWh to kgCO2/kWh if needed
        med = float(intensity_df["Intensity"].dropna().median())
        if med > 50:
            intensity_df["Intensity"] = intensity_df["Intensity"] / 1000.0

        intensity_df = intensity_df.dropna(subset=["Country", "Intensity"]).reset_index(drop=True)
        print(f"‚úÖ Processed carbon data for {len(intensity_df)} countries")

    except Exception as e:
        print(f"‚ùå ERROR loading carbon data: {e}")
        print("üí° Using sample carbon data as fallback...")
        # Create sample data similar to other codes
        countries = ["France", "Sweden", "Norway", "Switzerland", "Austria", "Germany", "United States", "China", "India"]
        intensities = [52, 41, 32, 45, 62, 385, 389, 537, 708]
        intensity_df = pd.DataFrame({
            "Country": countries,
            "Intensity": [i/1000.0 for i in intensities]  # Convert to kg/kWh
        })

    ensure_dir(carb_dir)
    carbon_df, summary_df = compute_carbon(perf_df, intensity_df,
                                           power_watts=device_power_watts,
                                           pue=pue, combine=combine)
    carb_excel = os.path.join(carb_dir, "carbon_results.xlsx")

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        to_excel({
            "carbon_results": carbon_df,
            "summary": summary_df,
            "intensity_input": intensity_df,
            "performance_reference": perf_df[["dimension", "pairs", "seed", "runtime_s"]]
        }, carb_excel)

    # Generate carbon plots
    plot_carbon(carbon_df, combine, carb_dir)
    print(f"‚úÖ Carbon analysis complete: {len(carbon_df)} entries")

    # Final summary
    success_count = perf_df["success"].sum()
    total_count = len(perf_df)
    success_rate = success_count / total_count if total_count > 0 else 0

    print("\n" + "="*60)
    print("üéâ QUANTUM SWAP TEST EXPERIMENT COMPLETE - RESULTS SUMMARY")
    print("="*60)
    print(f"üìÅ Performance:     {perf_excel}")
    print(f"üìÅ Scalability:     {scal_excel}")
    print(f"üìÅ Reliability:     {rel_excel}")
    print(f"üìÅ Carbon:          {carb_excel}")
    print(f"üñ•Ô∏è  Device:          {get_device_name()}")
    print(f"üìä Total runs:      {total_count}")
    print(f"‚úÖ Successful:      {success_count}")
    print(f"‚ùå Failed:          {total_count - success_count}")
    print(f"‚ö° Total runtime:   {perf_df['runtime_s'].sum():.2f}s")
    print(f"üî¨ Dimensions tested: {sorted(perf_df['dimension'].unique())}")
    print(f"üéØ Success rate:    {success_rate * 100:.1f}%")

    if success_count > 0:
        success_df = perf_df[perf_df["success"]]
        print(f"üìè Mean MSE:        {success_df['mse'].mean():.2e}")
        print(f"üìê Mean fidelity:   {success_df['fidelity'].mean():.3f}")
        print(f"üìä Mean cosine¬≤:   {success_df['mean_cosine_sq'].mean():.3f}")
    else:
        print(f"üìè Mean MSE:        N/A (no successful runs)")
        print(f"üìê Mean fidelity:   N/A (no successful runs)")
        print(f"üìä Mean cosine¬≤:   N/A (no successful runs)")

    print(f"\nüìÇ All results saved to:")
    for d in [perf_dir, scal_dir, rel_dir, carb_dir]:
        print(f"   ‚Ä¢ {d}")

    return perf_df

# ------------********-------------
# ------------********------------- Main execution for Kaggle
# ------------********-------------
if __name__ == "__main__":
    # Clean up GPU state
    safe_gpu_cleanup()

    print("üöÄ Starting Quantum SWAP Test Benchmark on Kaggle")
    print("=" * 50)

    # Run the complete experiment
    results_df = run_swap_test_experiment()

    if results_df is not None:
        # Display final results summary
        success_count = results_df["success"].sum()
        total_count = len(results_df)

        print("\nüìä FINAL RESULTS SUMMARY")
        print("=" * 30)
        print(f"Total experiments: {total_count}")
        print(f"Successful experiments: {success_count}")
        print(f"Failed experiments: {total_count - success_count}")
        print(f"Dimensions tested: {sorted(results_df['dimension'].unique())}")
        print(f"Vector pairs per run: {results_df['pairs'].iloc[0]}")
        print(f"Average runtime: {results_df['runtime_s'].mean():.6f}s")
        print(f"Success rate: {success_count / total_count * 100:.1f}%")

        if success_count > 0:
            success_df = results_df[results_df["success"]]
            print(f"Average MSE: {success_df['mse'].mean():.2e}")
            print(f"Average fidelity: {success_df['fidelity'].mean():.3f}")
            print(f"Average cosine¬≤: {success_df['mean_cosine_sq'].mean():.3f}")
        else:
            print(f"Average MSE: N/A")
            print(f"Average fidelity: N/A")
            print(f"Average cosine¬≤: N/A")

        print(f"Device used: {get_device_name()}")

        # Show folder structure
        print("\nüìÅ GENERATED OUTPUT STRUCTURE:")
        base_dir = '/kaggle/working'
        for root, dirs, files in os.walk(base_dir):
            # Only show our output directories
            if any(x in root for x in ['Performance', 'Scalability', 'Reliability', 'Carbon footprints']):
                level = root.replace(base_dir, '').count(os.sep)
                indent = ' ' * 2 * level
                print(f'{indent}üìÅ {os.path.basename(root)}/')
                sub_indent = ' ' * 2 * (level + 1)
                for file in files:
                    if file.endswith(('.xlsx', '.png')):
                        file_path = os.path.join(root, file)
                        size = os.path.getsize(file_path) / 1024  # KB
                        icon = "üìä" if file.endswith('.xlsx') else "üñºÔ∏è"
                        print(f'{sub_indent}{icon} {file} ({size:.1f} KB)')

        print("\n‚úÖ All Quantum SWAP Test deliverables generated successfully!")
        print("   ‚Ä¢ Performance/performance_results.xlsx + perf_*.png")
        print("   ‚Ä¢ Scalability/scalability_results.xlsx + scal_*.png")
        print("   ‚Ä¢ Reliability/reliability_results.xlsx + rel_*.png")
        print("   ‚Ä¢ Carbon footprints/carbon_by_country/carbon_results.xlsx + carbon_*.png")
    else:
        print("‚ùå Quantum SWAP Test benchmark failed - no results generated")

