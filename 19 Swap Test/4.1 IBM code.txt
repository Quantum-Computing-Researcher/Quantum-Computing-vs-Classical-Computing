#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# ----------------------------------------------------------------------------------------------------------------
# swap_test_ibm_hardware_light_notebook.py
#
# SWAP Test Benchmarks (Amplitude-encoded vectors)
#  - Core logic taken from swap_test_benchmarks.py (ideal/noiseless)
#  - Adds a LIGHT IBM hardware component:
#       * For each dimension, we run a small 3-qubit SWAP test circuit
#         for a few random state pairs on a real IBM backend.
#       * We measure hardware runtime and circuit depth.
#       * We add that hardware runtime into ONE performance row per dimension.
#  - Carbon uses total runtime (ideal + hardware), with power=65 W, PUE=1.2.

# ----------------------------------------------------------------------------------------------------------------

# Notes: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

# Code focuses on Performance, Scalability, Reliability, Carbon footprints
# Output folders are:
    #   Performance = runtime
    #   Scalability = growth of runtime as N increases (digits/bits).
    #   Reliability = success rate + dispersion across repetitions.
    #   Carbon footprints = derived *only* from PERFORMANCE totals
    #   (sum of successful wall-times), device power 65 Watts fixed for comparasion, PUE 1.2 fixed, 
    #   country carbon intensity (kg CO2/kWh). I did not use scalability or reliability results for CO2.

#      Carbon Data File: 
#      Uses ONLY Performance runtimes (not Scalability/Reliability), 
#      Placed on my Desktop Excel of country intensities "Filtered CO2 intensity 236 Countries.xlsx"
#      (CSV or XLSX; year column optional. I have selected --year-select latest.)
# ----------------------------------------------------------------------------------------------------------------


# ------------********------------ Imports
#These imports set up utilities for timing, memory tracking, and warning control during experiments.
#NumPy, pandas, and Matplotlib support numerical computation, data analysis, and headless plotting.
#Decimal helpers enable higher-precision arithmetic where needed.
#Qiskit runtime and circuit tools allow execution and transpilation of quantum programs on IBM backends.

import os
import time
import warnings
import tracemalloc
from typing import Dict, List, Tuple, Optional, Union

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

from decimal import Decimal, localcontext

from qiskit_ibm_runtime import QiskitRuntimeService, SamplerV2
from qiskit import QuantumCircuit
from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager

warnings.filterwarnings("ignore", category=UserWarning)

# ------------********------------
# ------------********------------ Utilities (filesystem, plotting, desktop file resolver)
# ------------********------------

#This helper ensures that an output directory exists before files are written.
#It safely creates the directory and ignores the case where it already exists.

def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)

#This function writes multiple pandas DataFrames into a single Excel workbook.
#If Excel writing fails, it falls back to exporting each table as a separate CSV file.

def write_excel(df_dict: Dict[str, pd.DataFrame], out_xlsx: str) -> None:
    """Write multiple DataFrames to one Excel file; fall back to CSVs if needed."""
    try:
        with pd.ExcelWriter(out_xlsx, engine="openpyxl") as writer:
            for sheet, df in df_dict.items():
                df.to_excel(writer, index=False, sheet_name=(sheet[:31] or "Sheet1"))
        print(f"[OK] Wrote Excel: {out_xlsx}")
    except Exception as e:
        print(f"[WARN] Could not write Excel ({e}). Falling back to CSVs.")
        base = os.path.splitext(out_xlsx)[0]
        for sheet, df in df_dict.items():
            path = f"{base}__{sheet}.csv"
            df.to_csv(path, index=False)
            print(f"[OK] Wrote CSV fallback: {path}")

#This utility saves a Matplotlib figure with consistent layout and resolution.
#It closes the figure after saving to free resources and reports the output location.
def save_fig(fig: plt.Figure, path: str, dpi: int = 150) -> None:
    fig.tight_layout()
    fig.savefig(path, dpi=dpi, bbox_inches="tight")
    plt.close(fig)
    print(f"[OK] Saved plot: {path}")

def resolve_desktop_file(user_arg: Optional[str],
                         default_basenames: List[str]) -> Optional[str]:
   
    #Resolve CO2 file on Desktop:
    #  - If user_arg looks like a path, try it directly, then Desktop\\user_arg,
     #   then user_arg + (.xlsx/.xls/.csv) on Desktop.
    #  - If user_arg is None, try default_basenames on Desktop.
    
    desktop = os.path.join(os.environ.get("USERPROFILE", ""), "Desktop")

    def exists(p: str) -> bool:
        return os.path.isfile(p)

    if user_arg:
        base = user_arg.strip().strip('"').strip("'")
        # 1) direct
        if exists(base):
            return os.path.abspath(base)
        # 2) Desktop\base
        cand = os.path.join(desktop, base)
        if exists(cand):
            return os.path.abspath(cand)
        # 3) add extensions if no extension
        root, ext = os.path.splitext(base)
        if not ext:
            for e in (".xlsx", ".xls", ".csv"):
                cand = os.path.join(desktop, root + e)
                if exists(cand):
                    return os.path.abspath(cand)
        # 4) case-insensitive name match
        tail = os.path.basename(base).lower()
        if os.path.isdir(desktop):
            for fname in os.listdir(desktop):
                fl = fname.lower()
                if fl == tail or (not ext and any(fl == tail + e for e in (".xlsx", ".xls", ".csv"))):
                    cand = os.path.join(desktop, fname)
                    if exists(cand):
                        return os.path.abspath(cand)
        return None

    # no user_arg: try defaults
    for b in default_basenames:
        for ext in ("", ".xlsx", ".xls", ".csv"):
            cand = os.path.join(desktop, b + ext)
            if exists(cand):
                return os.path.abspath(cand)
    return None

# ------------********------------
# ------------********------------ SWAP test math
# ------------********------------
#This function generates a list of dimensions that are powers of two within a specified range.
#It ensures a minimum dimension of 2 and iteratively builds valid sizes up to the maximum.

def dims_from_range(dmin: int, dmax: int) -> List[int]:
    """Powers of two between [dmin, dmax]."""
    if dmin < 2:
        dmin = 2
    dims = []
    d = 1
    while d < dmin:
        d *= 2
    while d <= dmax:
        dims.append(d)
        d *= 2
    return dims


#This function creates paired vectors for similarity experiments.
#It supports uniform or normal distributions and returns matched batches A and B.

def generate_pairs(dim: int, pairs: int, distribution: str,
                   rng: np.random.Generator) -> Tuple[np.ndarray, np.ndarray]:
    if distribution == "uniform":
        A = rng.uniform(-1.0, 1.0, size=(pairs, dim)).astype(np.float64)
        B = rng.uniform(-1.0, 1.0, size=(pairs, dim)).astype(np.float64)
    else:  # "normal"
        A = rng.standard_normal(size=(pairs, dim), dtype=np.float64)
        B = rng.standard_normal(size=(pairs, dim), dtype=np.float64)
    return A, B

#This routine computes dot products and cosine similarities for batches of vector pairs.
#It optionally enforces normalization to mimic amplitude encoding and returns cosÂ² values.
def cosine_batch(A: np.ndarray, B: np.ndarray,
                 enforce_normalize: bool = True) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Returns (dot, cosine, cosine_squared). If enforce_normalize=True, we normalize
    vectors to unit length (amplitude encoding requirement).
    """
    nA = np.linalg.norm(A, axis=1)
    nB = np.linalg.norm(B, axis=1)
    dot = np.einsum("ij,ij->i", A, B)

    cos = dot / (nA * nB + 1e-16)
    cos = np.clip(cos, -1.0, 1.0)

    if enforce_normalize:
        A /= (nA[:, None] + 1e-16)
        B /= (nB[:, None] + 1e-16)

    cos_sq = cos ** 2
    return dot, cos, cos_sq

#This helper computes the ideal SWAP-test probability p0 from cosine-squared values.
#It represents the noiseless theoretical relationship used in quantum similarity tests.

def swap_p0_from_cos_sq(cos_sq: np.ndarray) -> np.ndarray:
    """Ideal SWAP test: p0 = (1 + cos^2)/2."""
    return 0.5 * (1.0 + cos_sq)

#This function simulates measurement outcomes by sampling ancilla results.
#It returns both the estimated p0 and a transformed estimator for cosine squared.

def sample_p0(p0: np.ndarray, shots: int, rng: np.random.Generator) -> Tuple[np.ndarray, np.ndarray]:
    """
    Sample ancilla outcomes with given p0 per pair. Returns (p0_hat, s_hat),
    where s_hat = 2*p0_hat - 1 is an estimator of cos^2.
    """
    if shots <= 0:
        raise ValueError("shots must be >= 1 for sampling.")
    k = rng.binomial(n=shots, p=np.clip(p0, 0.0, 1.0))
    p0_hat = k.astype(np.float64) / float(shots)
    s_hat = 2.0 * p0_hat - 1.0
    return p0_hat, s_hat

#This helper computes cosine similarity using high-precision arithmetic.
#It serves as a reference for validating numerical accuracy when sampling is disabled.

def cosine_high_prec(a: np.ndarray, b: np.ndarray, prec: int = 60) -> float:
    """High-precision cosine for reliability (noiseless case)."""
    with localcontext() as ctx:
        ctx.prec = prec
        d_dot = Decimal(0)
        d_n1 = Decimal(0)
        d_n2 = Decimal(0)
        for x, y in zip(a, b):
            dx = Decimal(str(float(x)))
            dy = Decimal(str(float(y)))
            d_dot += dx * dy
            d_n1 += dx * dx
            d_n2 += dy * dy
        if d_n1 == 0 or d_n2 == 0:
            return 0.0
        denom = d_n1.sqrt() * d_n2.sqrt()
        try:
            val = d_dot / denom
        except Exception:
            return 0.0
        return float(max(-1.0, min(1.0, val)))

# ------------********------------
# ------------********------------ Performance / reliability work units (single-threaded)
# ------------********------------

#This worker function runs a single performance benchmark for cosine similarity computation.
#It measures runtime and peak memory usage while collecting aggregate statistics over vector pairs.
def _perf_task(dim: int, pairs: int, distribution: str,
               enforce_norm: bool, repeat: int,
               seed: int, shots: int) -> dict:
    rng = np.random.default_rng(seed + dim * 101 + repeat * 17)
    A, B = generate_pairs(dim, pairs, distribution, rng)

    tracemalloc.start()
    t0 = time.perf_counter()

    _, cos, cos_sq = cosine_batch(A, B, enforce_normalize=enforce_norm)
    p0 = swap_p0_from_cos_sq(cos_sq)

    if shots and shots > 0:
        p0_hat, s_hat = sample_p0(p0, shots, rng)
        mean_s_measure = float(np.mean(s_hat))
    else:
        mean_s_measure = float(np.mean(2.0 * p0 - 1.0))

    runtime = time.perf_counter() - t0
    _, peak = tracemalloc.get_traced_memory()
    tracemalloc.stop()

    return {
        "dimension": dim,
        "pairs": pairs,
        "repeat": repeat,
        "runtime_sec": runtime,
        "peak_mem_mb": peak / (1024 ** 2),
        "mean_p0": float(np.mean(p0)),
        "mean_cosine_sq": float(np.mean(cos_sq)),
        "mean_swap_estimate": mean_s_measure,
    }

#This helper evaluates numerical reliability on a small subset of vector pairs.
#It compares standard cosine results against a high-precision reference and records absolute errors.
def _reli_subset(dim: int, pairs_for_rel: int, distribution: str,
                 enforce_norm: bool, repeat: int, seed: int, shots: int) -> pd.DataFrame:
    rng = np.random.default_rng(seed + 7919 + dim * 23 + repeat)
    k = pairs_for_rel
    A, B = generate_pairs(dim, k, distribution, rng)
    _, cos, cos_sq = cosine_batch(A, B, enforce_normalize=enforce_norm)
    p0 = swap_p0_from_cos_sq(cos_sq)

    if shots and shots > 0:
        _, s_hat = sample_p0(p0, shots, rng)
        errs = np.abs(s_hat - cos_sq)
    else:
        errs = []
        for i in range(k):
            ref_cos = cosine_high_prec(A[i], B[i], prec=60)
            errs.append(abs((ref_cos ** 2) - float(cos_sq[i])))
        errs = np.array(errs, dtype=np.float64)

    return pd.DataFrame({
        "dimension": [dim] * k,
        "repeat": [repeat] * k,
        "pair_index": list(range(k)),
        "abs_error": errs
    })

def run_performance(dims: List[int], pairs: int, repeats: int,
                    distribution: str, enforce_norm: bool,
                    seed: int, shots: int) -> pd.DataFrame:
    rows = []
    for d in dims:
        for r in range(repeats):
            rows.append(_perf_task(d, pairs, distribution, enforce_norm, r, seed, shots))
    return pd.DataFrame(rows)

def run_reliability(dims: List[int], pairs_for_rel: int,
                    distribution: str, enforce_norm: bool,
                    seed: int, repeats: int, shots: int) -> pd.DataFrame:
    dfs = []
    for d in dims:
        for r in range(repeats):
            dfs.append(_reli_subset(d, pairs_for_rel, distribution, enforce_norm, r, seed, shots))
    if not dfs:
        return pd.DataFrame(columns=["dimension", "repeat", "pair_index", "abs_error"])
    return pd.concat(dfs, ignore_index=True)

def run_scalability_pairs(dim_heavy: int, base_pairs: int, distribution: str,
                          enforce_norm: bool, seed: int,
                          multipliers: List[float], repeats: int,
                          shots: int) -> pd.DataFrame:
    pgrid = sorted(set(max(1, int(round(base_pairs * m))) for m in multipliers))
    rows = []
    for p in pgrid:
        for r in range(repeats):
            rows.append(_perf_task(dim_heavy, p, distribution, enforce_norm, r, seed, shots))
    df = pd.DataFrame(rows)
    df["is_pairs_scaling"] = True
    return df

# ------------********------------
# ------------********------------ Carbon logic & plots (from ideal script)
# ------------********------------

def load_country_co2(path: str, year_select: str = "latest") -> pd.DataFrame:
    if path.lower().endswith(".csv"):
        df = pd.read_csv(path)
    else:
        df = pd.read_excel(path)
    df.columns = [str(c).strip().lower() for c in df.columns]

    cname = next((c for c in df.columns if "country" in c or c in ("name","nation")), None)
    if cname is None:
        raise ValueError("Could not find a 'country' column.")

    yname = next((c for c in df.columns if "year" in c), None)
    cand = [c for c in df.columns if "intensity" in c]
    if not cand:
        cand = [c for c in df.columns if ("co2" in c and "kwh" in c)]
    if not cand:
        cand = [c for c in df.columns if (("kg" in c or "g" in c) and "kwh" in c)]
    if not cand:
        raise ValueError("No intensity column found.")
    icol = cand[0]

    cols = [cname, icol] + ([yname] if yname else [])
    out = df[cols].dropna().copy()
    out.columns = ["country","intensity_raw"] + (["year"] if yname else [])
    out["intensity_raw"] = pd.to_numeric(out["intensity_raw"], errors="coerce")
    out = out.dropna(subset=["intensity_raw"])

    med = float(np.nanmedian(out["intensity_raw"].values))
    if med > 10.0:
        out["kg_per_kwh"] = out["intensity_raw"] / 1000.0
    else:
        out["kg_per_kwh"] = out["intensity_raw"]

    out["country"] = out["country"].astype(str).str.strip().str.title()
    if yname and year_select == "latest":
        out = out.sort_values(["country","year"]).groupby("country", as_index=False).tail(1)

    cols_out = ["country","kg_per_kwh"] + (["year"] if yname else [])
    return out[cols_out].drop_duplicates()

def compute_emissions(perf_df: pd.DataFrame,
                      co2_df: pd.DataFrame,
                      power_watts: float,
                      pue: float) -> pd.DataFrame:
    perf = perf_df.copy()
    perf["energy_kwh"] = (perf["runtime_sec"] * power_watts) / 3.6e6
    perf["energy_kwh"] *= pue
    co2 = co2_df.rename(columns={"kg_per_kwh":"kgco2_per_kwh"}).copy()
    perf["_k"] = 1; co2["_k"] = 1
    joined = perf.merge(co2, on="_k").drop(columns="_k")
    joined["emissions_kgCO2"] = joined["energy_kwh"] * joined["kgco2_per_kwh"]
    return joined

def build_worstcase_country_table(perf_df: pd.DataFrame,
                                  co2_df: pd.DataFrame,
                                  power_watts: float,
                                  pue: float) -> Tuple[pd.DataFrame, dict]:
    dim_heavy = int(perf_df["dimension"].max())
    mask = perf_df["dimension"] == dim_heavy
    mean_runtime_s = float(perf_df.loc[mask, "runtime_sec"].mean())
    energy_kwh = mean_runtime_s * power_watts / 3.6e6 * pue

    tbl = co2_df.copy()
    if "year" not in tbl.columns:
        tbl["year"] = pd.NA

    out = pd.DataFrame({
        "Country": tbl["country"].astype(str),
        "Year": tbl["year"],
        "Intensity": tbl["kg_per_kwh"],
        "kWh": energy_kwh,
    })
    out["kgCO2e"] = out["Intensity"] * out["kWh"]
    out = out.sort_values("kgCO2e", ascending=False).reset_index(drop=True)

    meta = {
        "dimension_heavy": dim_heavy,
        "mean_runtime_s": mean_runtime_s,
        "power_watts": power_watts,
        "pue": pue,
        "kWh_used": energy_kwh,
    }
    return out, meta

def plot_carbon_distribution(worst_table: pd.DataFrame, out_path: str) -> None:
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(worst_table["kgCO2e"].values, bins=30)
    ax.set_xlabel("kg CO2e")
    ax.set_title("Carbon: Emission distribution (worst-case scenario)")
    save_fig(fig, out_path)

def plot_carbon_topN(worst_table: pd.DataFrame, N: int, out_path: str) -> None:
    s = worst_table.sort_values("kgCO2e", ascending=False).head(N)
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.barh(s["Country"], s["kgCO2e"])
    ax.invert_yaxis()
    ax.set_xlabel("kg CO2e")
    ax.set_title(f"Carbon: Top {N} countries (worst-case scenario)")
    save_fig(fig, out_path)

def plot_carbon_median_vs_dimension(carbon_df: pd.DataFrame, out_path: str) -> None:
    med = carbon_df.groupby("dimension")["emissions_kgCO2"].median().reset_index()
    fig, ax = plt.subplots(figsize=(7, 5))
    ax.plot(med["dimension"], med["emissions_kgCO2"], marker="o")
    ax.set_xscale("log", base=2)
    ax.set_xlabel("Dimension")
    ax.set_ylabel("Median emissions across countries (kg CO2e)")
    ax.set_title("Median emissions vs dimension")
    save_fig(fig, out_path)

# ------------********------------
# ------------********------------ Performance / reliability / scalability plots
# ------------********------------

def plot_perf_runtime_vs_dimension(perf_df: pd.DataFrame, out_path: str) -> None:
    sub = perf_df.groupby("dimension", as_index=False)["runtime_sec"].mean()
    fig, ax = plt.subplots(figsize=(7, 5))
    ax.plot(sub["dimension"], sub["runtime_sec"], marker="o")
    ax.set_xscale("log", base=2)
    ax.set_yscale("log")
    ax.set_xlabel("Dimension")
    ax.set_ylabel("Runtime (s)")
    ax.set_title("Performance: runtime vs dimension (SWAP test, IBM)")
    save_fig(fig, out_path)

def plot_perf_memory_vs_dimension(perf_df: pd.DataFrame, out_path: str) -> None:
    sub = perf_df.groupby("dimension", as_index=False)["peak_mem_mb"].mean()
    fig, ax = plt.subplots(figsize=(7, 5))
    ax.plot(sub["dimension"], sub["peak_mem_mb"], marker="s")
    ax.set_xscale("log", base=2)
    ax.set_xlabel("Dimension")
    ax.set_ylabel("Peak allocated (MB)")
    ax.set_title("Performance: memory vs dimension (SWAP test, IBM)")
    save_fig(fig, out_path)

def plot_rel_error_vs_dimension(rel_df: pd.DataFrame, out_path: str) -> None:
    if rel_df.empty:
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.text(0.5,0.5,"No reliability data",ha="center",va="center")
        ax.axis("off")
        save_fig(fig, out_path)
        return
    g = rel_df.groupby("dimension", as_index=False)["abs_error"].agg(["mean","max"]).reset_index()
    fig, ax = plt.subplots(figsize=(7, 5))
    ax.plot(g["dimension"], g["mean"], marker="o", label="mean abs error")
    ax.plot(g["dimension"], g["max"], marker="s", label="max abs error")
    ax.set_xscale("log", base=2)
    ax.set_yscale("log")
    ax.set_xlabel("Dimension")
    ax.set_ylabel("Absolute error")
    ax.set_title("Reliability: SWAP estimate vs ground truth")
    ax.legend()
    save_fig(fig, out_path)

def plot_rel_error_histogram(rel_df: pd.DataFrame, out_path: str) -> None:
    if rel_df.empty:
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.text(0.5,0.5,"No reliability data",ha="center",va="center")
        ax.axis("off")
        save_fig(fig, out_path)
        return
    d_max = int(rel_df["dimension"].max())
    sub = rel_df[rel_df["dimension"] == d_max]
    fig, ax = plt.subplots(figsize=(7, 5))
    ax.hist(sub["abs_error"].values, bins=30)
    ax.set_xlabel("Absolute error")
    ax.set_ylabel("Count")
    ax.set_title(f"Reliability: error distribution at dimension {d_max}")
    save_fig(fig, out_path)

def plot_rel_error_boxplot_by_dimension(rel_df: pd.DataFrame, out_path: str) -> None:
    if rel_df.empty:
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.text(0.5,0.5,"No reliability data",ha="center",va="center")
        ax.axis("off")
        save_fig(fig, out_path)
        return
    dims_sorted = sorted(rel_df["dimension"].unique())
    data = [rel_df[rel_df["dimension"] == d]["abs_error"].values for d in dims_sorted]
    fig, ax = plt.subplots(figsize=(8, 5))
    ax.boxplot(data, labels=[str(d) for d in dims_sorted], showfliers=False)
    ax.set_xlabel("Dimension")
    ax.set_ylabel("Absolute error")
    ax.set_title("Reliability: error boxplot by dimension")
    save_fig(fig, out_path)

def plot_pairs_scaling(perf_pairs_df: pd.DataFrame, out_path: str) -> None:
    sub = perf_pairs_df.groupby("pairs", as_index=False)["runtime_sec"].mean().sort_values("pairs")
    fig, ax = plt.subplots(figsize=(7, 5))
    ax.plot(sub["pairs"], sub["runtime_sec"], marker="o")
    ax.set_xscale("log")
    ax.set_yscale("log")
    ax.set_xlabel("Number of vector pairs")
    ax.set_ylabel("Runtime (s)")
    ax.set_title("Scalability: runtime vs number of pairs (largest dimension, IBM)")
    save_fig(fig, out_path)

def plot_perf_runtime_vs_dimension_loglog(perf_df: pd.DataFrame, out_path: str) -> None:
    sub = perf_df.groupby("dimension", as_index=False)["runtime_sec"].mean()
    fig, ax = plt.subplots(figsize=(7, 5))
    ax.plot(sub["dimension"], sub["runtime_sec"], marker="o")
    ax.set_xscale("log", base=2)
    ax.set_yscale("log")
    ax.set_xlabel("Dimension")
    ax.set_ylabel("Runtime (s)")
    ax.set_title("Scalability: runtime vs dimension (log-log, IBM)")
    save_fig(fig, out_path)

def plot_runtime_per_pair_vs_pairs(perf_pairs_df: pd.DataFrame, out_path: str) -> None:
    sub = perf_pairs_df.groupby("pairs", as_index=False)["runtime_sec"].mean().sort_values("pairs")
    sub["runtime_per_pair"] = sub["runtime_sec"] / sub["pairs"]
    fig, ax = plt.subplots(figsize=(7, 5))
    ax.plot(sub["pairs"], sub["runtime_per_pair"], marker="o")
    ax.set_xscale("log")
    ax.set_xlabel("Number of vector pairs")
    ax.set_ylabel("Runtime per pair (s/pair)")
    ax.set_title("Scalability: runtime per pair vs pairs (largest dimension, IBM)")
    save_fig(fig, out_path)

# ------------********------------
# ------------********------------ IBM hardware SWAP test (light)
# ------------********------------

def build_swap_test_circuit(ry1: float, rz1: float,
                            ry2: float, rz2: float) -> QuantumCircuit:
    """
    Minimal 3-qubit SWAP test:
      - qubit 0: ancilla
      - qubit 1: |psi>
      - qubit 2: |phi>
    We prepare |psi>, |phi> with simple Ry,Rz rotations.
    """
    qc = QuantumCircuit(3, 1)
    # Prepare data states
    qc.ry(ry1, 1)
    qc.rz(rz1, 1)
    qc.ry(ry2, 2)
    qc.rz(rz2, 2)
    # SWAP test
    qc.h(0)
    qc.cswap(0, 1, 2)
    qc.h(0)
    qc.measure(0, 0)
    return qc

def get_ibm_sampler(backend_name: str, shots: int):
    """
    Initialize QiskitRuntimeService and SamplerV2 for a given backend.
    Assumes IBM account is already saved on this machine.
    """
    print("[ibm] Initializing QiskitRuntimeService ...")
    service = QiskitRuntimeService()
    backend = service.backend(backend_name)
    print(f"[ibm] Using backend: {backend.name}")
    print(f"[ibm]   num_qubits={backend.num_qubits}, simulator={getattr(backend, 'simulator', False)}")
    print(f"[ibm]   default shots for hardware benchmark: {shots}")
    pm = generate_preset_pass_manager(backend=backend, optimization_level=1)
    sampler = SamplerV2(mode=backend)
    return backend, sampler, pm

def hardware_swap_test_for_dim(
    dim: int,
    backend,
    sampler: SamplerV2,
    pass_manager,
    hw_pairs_per_dim: int,
    hw_shots: int,
    seed: int,
) -> dict:
    """
    Run a LIGHT hardware SWAP test micro-bench for a given dimension:
      - Build up to hw_pairs_per_dim 3-qubit SWAP circuits with random states.
      - Transpile via pass_manager.
      - Run with SamplerV2, record:
          * hardware_runtime_sec
          * mean/max circuit depth
          * total counts
      - Return metrics dict.
    """
    if backend.num_qubits < 3:
        print(f"[ibm-swap] Backend {backend.name} has <3 qubits. Skipping hardware for dim={dim}.")
        return {
            "hardware_runtime_sec": 0.0,
            "hardware_depth_mean": 0.0,
            "hardware_depth_max": 0,
            "hardware_circuits": 0,
            "hardware_shots": int(hw_shots),
            "hardware_counts_total": 0,
        }

    rng = np.random.default_rng(seed + dim * 10007)
    n_circs = max(1, int(hw_pairs_per_dim))
    logical_circs = []
    for _ in range(n_circs):
        ry1, rz1, ry2, rz2 = rng.uniform(0, 2*np.pi, size=4)
        logical_circs.append(build_swap_test_circuit(ry1, rz1, ry2, rz2))

    isa_circs = pass_manager.run(logical_circs)
    depths = [c.depth() for c in isa_circs]
    print(f"[ibm-swap] Submitting {n_circs} SWAP circuits for dim={dim} (shots={hw_shots}) ...")

    t0_hw = time.perf_counter()
    job = sampler.run(isa_circs, shots=int(hw_shots))
    primitive_result = job.result()
    hw_runtime = time.perf_counter() - t0_hw
    print(f"[ibm-swap] Hardware job for dim={dim} finished in {hw_runtime:.3f} s.")

    total_counts = 0
    for pub_res in primitive_result:
        joined = pub_res.join_data()
        counts = joined.get_counts()
        total_counts += sum(counts.values())

    return {
        "hardware_runtime_sec": float(hw_runtime),
        "hardware_depth_mean": float(np.mean(depths) if depths else 0.0),
        "hardware_depth_max": int(max(depths) if depths else 0),
        "hardware_circuits": int(n_circs),
        "hardware_shots": int(hw_shots),
        "hardware_counts_total": int(total_counts),
    }

# ------------********------------
# ------------********------------ Notebook entry point
# ------------********------------

def run_swap_test_ibm_hardware_notebook(
    # Problem size & data (CLI parity)
    dim_min: int = 128,
    dim_max: int = 4096,
    pairs: int = 1000,
    repeats: int = 2,
    distribution: str = "normal",
    normalize: bool = True,
    shots: int = 4096,
    # Carbon & file inputs
    excel_filename: str = "Filtered CO2 intensity 236 Countries.xlsx",
    device_power_watts: float = 65.0,
    pue: float = 1.2,
    year_select: str = "latest",
    outdir: Optional[str] = None,
    seed: int = 7,
    # IBM hardware params (light)
    backend_name: str = "ibm_torino",
    hw_pairs_per_dim: int = 4,
    hw_shots: int = 1024,
):
    
# ------------********----------------------********---------------------********------------
    """
    SWAP Test benchmarks with IBM hardware in the loop (lightweight).

    Parameters mirror our CLI:
      - dim_min, dim_max, pairs, repeats, distribution, normalize, shots.
      - excel_filename, device_power_watts=65, pue=1.2, year_select, outdir.
    Plus IBM hardware options:
      - backend_name: IBM backend name.
      - hw_pairs_per_dim: # of tiny SWAP circuits per dimension on hardware.
      - hw_shots: shots per circuit on hardware.

    Behavior:
      - Runs the same classical SWAP-test benchmarks as the ideal script.
      - For each dimension, runs a small SWAP-test job on IBM hardware.
      - Adds that hardware runtime into one performance row per dimension.
      - Computes carbon from total runtime (ideal + hardware).
      - Produces four folders under outdir:
          Performance, Scalability, Reliability, Carbon.
    """

# ------------********----------------------********---------------------********------------


    # ---- Dimensions ----
    dims = dims_from_range(dim_min, dim_max)
    if not dims:
        raise ValueError("No powers of two found in the requested dimension range.")

    print("[swap-ibm-light] SWAP Test IBM hardware benchmark")
    print("  dims:", dims)
    print(f"  pairs={pairs}, repeats={repeats}, distribution={distribution}, shots={shots}")
    print(f"  normalize={normalize}")
    print(f"  backend={backend_name}, hw_pairs_per_dim={hw_pairs_per_dim}, hw_shots={hw_shots}")
    print(f"  excel_filename={excel_filename}, power={device_power_watts} W, PUE={pue}, year_select={year_select}")

    enforce_norm = True  # amplitude encoding always normalized; 'normalize' kept for CLI parity

# ------------********---------------- Output directories ----
    if outdir is None:
        root = os.getcwd()
    else:
        root = os.path.abspath(os.path.expandvars(outdir))

    perf_dir = os.path.join(root, "Performance")
    scal_dir = os.path.join(root, "Scalability")
    reli_dir = os.path.join(root, "Reliability")
    carb_dir = os.path.join(root, "Carbon")
    for d in (perf_dir, scal_dir, reli_dir, carb_dir):
        ensure_dir(d)

    print("[INFO] Output root:", root)
    print("       - Performance ->", perf_dir)
    print("       - Scalability ->", scal_dir)
    print("       - Reliability ->", reli_dir)
    print("       - Carbon      ->", carb_dir)

# ------------********--------------- Ideal PERFORMANCE ----
    print("[INFO] Running ideal performance benchmark (classical SWAP math) ...")
    perf_df = run_performance(
        dims=dims,
        pairs=pairs,
        repeats=repeats,
        distribution=distribution,
        enforce_norm=enforce_norm,
        seed=seed,
        shots=shots,
    )

    perf_sum = perf_df.groupby("dimension", as_index=False).agg(
        pairs=("pairs", "max"),
        mean_runtime_sec=("runtime_sec", "mean"),
        std_runtime_sec=("runtime_sec", "std"),
        mean_peak_mem_mb=("peak_mem_mb", "mean"),
        std_peak_mem_mb=("peak_mem_mb", "std"),
        mean_p0=("mean_p0", "mean"),
        mean_cosine_sq=("mean_cosine_sq", "mean"),
        mean_swap_estimate=("mean_swap_estimate", "mean"),
    )

# ------------********---------------- Ideal RELIABILITY ----
    print("[INFO] Running reliability benchmark (subset of pairs) ...")
    pairs_for_rel = max(1, min(10, pairs))
    rel_raw = run_reliability(
        dims=dims,
        pairs_for_rel=pairs_for_rel,
        distribution=distribution,
        enforce_norm=enforce_norm,
        seed=seed,
        repeats=repeats,
        shots=shots,
    )
    if rel_raw.empty:
        rel_sum = pd.DataFrame({"dimension": [], "mean_abs_error": [], "max_abs_error": [], "n": []})
    else:
        g = rel_raw.groupby("dimension", as_index=False)
        rel_sum = g.agg(
            mean_abs_error=("abs_error", "mean"),
            max_abs_error=("abs_error", "max"),
            n=("abs_error", "count"),
        )

# ------------********---------------- Ideal SCALABILITY (pairs at largest dimension) ----
    print("[INFO] Running scalability micro-bench (pairs at largest dimension) ...")
    dim_heavy = max(dims)
    try:
        mults = [float(x.strip()) for x in "0.25,0.5,1,2".split(",")]
    except Exception:
        mults = [0.5, 1.0, 2.0]
    pairs_scal_df = run_scalability_pairs(
        dim_heavy=dim_heavy,
        base_pairs=pairs,
        distribution=distribution,
        enforce_norm=enforce_norm,
        seed=seed,
        multipliers=mults,
        repeats=repeats,
        shots=shots,
    )
    scaling_fit = pd.DataFrame()
    if len(dims) >= 2:
        sub = perf_df.groupby("dimension", as_index=False)["runtime_sec"].mean()
        x = np.log(sub["dimension"].values + 1e-16)
        y = np.log(sub["runtime_sec"].values + 1e-16)
        alpha, _ = np.polyfit(x, y, 1)
        scaling_fit = pd.DataFrame({"fit_parameter": ["alpha_dim_scaling"], "estimate": [alpha]})

# ------------********---------------- IBM hardware micro-bench ----
    print("[INFO] Running IBM hardware SWAP micro-benchmarks (light) ...")
    backend, sampler, pm = get_ibm_sampler(backend_name, hw_shots)
    hw_metrics_by_dim: Dict[int, dict] = {}

    for d in dims:
        hw_metrics_by_dim[d] = hardware_swap_test_for_dim(
            dim=d,
            backend=backend,
            sampler=sampler,
            pass_manager=pm,
            hw_pairs_per_dim=hw_pairs_per_dim,
            hw_shots=hw_shots,
            seed=seed,
        )

    # Merge hardware metrics into perf_df
    perf_df_ibm = perf_df.copy()
    perf_df_ibm["hardware_runtime_sec"] = 0.0
    perf_df_ibm["hardware_depth_mean"] = 0.0
    perf_df_ibm["hardware_depth_max"] = 0
    perf_df_ibm["hardware_circuits"] = 0
    perf_df_ibm["hardware_shots"] = int(hw_shots)
    perf_df_ibm["hardware_counts_total"] = 0

    for d in dims:
        hw = hw_metrics_by_dim.get(d, None)
        if hw is None:
            continue
        mask = perf_df_ibm["dimension"] == d
        idx = perf_df_ibm[mask].sort_values("repeat").index.tolist()
        if not idx:
            continue
        first_idx = idx[0]
        perf_df_ibm.loc[first_idx, "hardware_runtime_sec"] = hw["hardware_runtime_sec"]
        perf_df_ibm.loc[first_idx, "hardware_depth_mean"] = hw["hardware_depth_mean"]
        perf_df_ibm.loc[first_idx, "hardware_depth_max"] = hw["hardware_depth_max"]
        perf_df_ibm.loc[first_idx, "hardware_circuits"] = hw["hardware_circuits"]
        perf_df_ibm.loc[first_idx, "hardware_shots"] = hw["hardware_shots"]
        perf_df_ibm.loc[first_idx, "hardware_counts_total"] = hw["hardware_counts_total"]
        # add hardware runtime into total runtime_sec
        perf_df_ibm.loc[first_idx, "runtime_sec"] = (
            perf_df_ibm.loc[first_idx, "runtime_sec"] + hw["hardware_runtime_sec"]
        )

    # ------------********-------------
   # ------------********------------- PERFORMANCE outputs
    # ------------********-------------
    perf_sum_ibm = perf_df_ibm.groupby("dimension", as_index=False).agg(
        pairs=("pairs", "max"),
        mean_runtime_sec=("runtime_sec", "mean"),
        std_runtime_sec=("runtime_sec", "std"),
        mean_hw_runtime_sec=("hardware_runtime_sec", "mean"),
        mean_peak_mem_mb=("peak_mem_mb", "mean"),
        std_peak_mem_mb=("peak_mem_mb", "std"),
        mean_p0=("mean_p0", "mean"),
        mean_cosine_sq=("mean_cosine_sq", "mean"),
        mean_swap_estimate=("mean_swap_estimate", "mean"),
    )

    perf_xlsx = os.path.join(perf_dir, "performance_ibm_hardware.xlsx")
    write_excel(
        {
            "raw": perf_df_ibm.sort_values(["dimension", "repeat"]),
            "summary": perf_sum_ibm.sort_values("dimension"),
        },
        perf_xlsx,
    )
    plot_perf_runtime_vs_dimension(perf_df_ibm, os.path.join(perf_dir, "runtime_vs_dimension_ibm.png"))
    plot_perf_memory_vs_dimension(perf_df_ibm, os.path.join(perf_dir, "memory_vs_dimension_ibm.png"))

    # ------------********-------------
    # ------------********------------- RELIABILITY outputs
    # ------------********-------------
    reli_xlsx = os.path.join(reli_dir, "reliability_ibm_hardware.xlsx")
    write_excel(
        {
            "errors_raw": rel_raw.sort_values(["dimension", "repeat", "pair_index"]),
            "errors_summary": rel_sum.sort_values("dimension"),
        },
        reli_xlsx,
    )
    plot_rel_error_vs_dimension(rel_raw, os.path.join(reli_dir, "error_vs_dimension_ibm.png"))
    plot_rel_error_histogram(rel_raw, os.path.join(reli_dir, "error_histogram_at_largest_dimension_ibm.png"))
    plot_rel_error_boxplot_by_dimension(rel_raw, os.path.join(reli_dir, "error_boxplot_by_dimension_ibm.png"))

    # ------------********-------------
    # ------------********-------------SCALABILITY outputs
    # ------------********-------------
    scal_xlsx = os.path.join(scal_dir, "scalability_ibm_hardware.xlsx")
    write_excel(
        {
            "perf_raw": perf_df_ibm.sort_values(["dimension", "repeat"]),
            "pairs_scaling_raw": pairs_scal_df.sort_values(["pairs", "repeat"]),
            "scaling_fit": scaling_fit,
        },
        scal_xlsx,
    )
    plot_pairs_scaling(pairs_scal_df, os.path.join(scal_dir, "runtime_vs_pairs_at_largest_dimension_ibm.png"))
    plot_perf_runtime_vs_dimension_loglog(perf_df_ibm, os.path.join(scal_dir, "runtime_vs_dimension_loglog_ibm.png"))
    plot_runtime_per_pair_vs_pairs(pairs_scal_df, os.path.join(scal_dir, "runtime_per_pair_vs_pairs_ibm.png"))

    # ------------********-------------
    # ------------********------------- CARBON outputs (Performance-only, with hardware time included)
    # ------------********-------------
    desktop = os.path.join(os.environ.get("USERPROFILE", ""), "Desktop")
    default_co2_basenames = [
        "Filtered CO2 intensity 236 Countries",
        "countries_co2",
        "co2_countries",
    ]
    co2_path = resolve_desktop_file(excel_filename, default_co2_basenames)

    carbon_df = None
    carbon_meta_df = None
    if co2_path and os.path.isfile(co2_path):
        print(f"[INFO] Using CO2 file: {co2_path}")
        co2_df = load_country_co2(co2_path, year_select=year_select)
        carbon_df = compute_emissions(
            perf_df_ibm,
            co2_df,
            power_watts=device_power_watts,
            pue=pue,
        )
        worst_table, meta = build_worstcase_country_table(
            perf_df_ibm,
            co2_df,
            power_watts=device_power_watts,
            pue=pue,
        )
        carbon_meta_df = pd.DataFrame([meta])
        carb_xlsx = os.path.join(carb_dir, "carbon_footprint_ibm_hardware.xlsx")
        write_excel(
            {
                "co2_by_country": (co2_df.rename(columns={"kg_per_kwh":"kgco2_per_kwh"})
                                   if "kg_per_kwh" in co2_df.columns else co2_df),
                "emissions_all": carbon_df.sort_values(["dimension", "country"]),
                "worst_case_table": worst_table,
                "worst_case_metadata": carbon_meta_df,
            },
            carb_xlsx,
        )
        plot_carbon_distribution(worst_table, os.path.join(carb_dir, "carbon_distribution_ibm.png"))
        plot_carbon_topN(worst_table, 15, os.path.join(carb_dir, "carbon_top15_ibm.png"))
        plot_carbon_median_vs_dimension(carbon_df, os.path.join(carb_dir, "median_emissions_vs_dimension_ibm.png"))
    else:
        print("[WARN] CO2 file not found; writing placeholder carbon workbook.")
        carb_xlsx = os.path.join(carb_dir, "carbon_placeholder_ibm_hardware.xlsx")
        placeholder = pd.DataFrame({
            "note": ["CO2 file not provided or not found on Desktop."],
            "hint": ["Place 'Filtered CO2 intensity 236 Countries.xlsx' on Desktop or pass full path via excel_filename."],
        })
        write_excel({"info": placeholder}, carb_xlsx)

    print("\n[DONE] SWAP Test IBM hardware benchmark complete.")
    print(f"Performance Excel:  {perf_xlsx}")
    print(f"Scalability Excel:  {scal_xlsx}")
    print(f"Reliability Excel:  {reli_xlsx}")
    print(f"Carbon Excel:       {os.path.join(carb_dir, 'carbon_footprint_ibm_hardware.xlsx')}")
    print("Folders under:", root)
    print("  - Performance")
    print("  - Scalability")
    print("  - Reliability")
    print("  - Carbon")

    return {
        "perf_df": perf_df_ibm,
        "rel_df": rel_raw,
        "perf_dir": perf_dir,
        "scal_dir": scal_dir,
        "reli_dir": reli_dir,
        "carb_dir": carb_dir,
        "carbon_df": carbon_df,
        "carbon_summary": carbon_meta_df,
    }
